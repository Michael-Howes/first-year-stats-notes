\include{preamble}
\include{definitions}



\title{STATS310A - Lecture 4}
\author{Persi Diaconis\\ Scribed by Michael Howes}
\date{09/30/21}

\pagestyle{fancy}
\fancyhf{}
\rhead{STATS310A - Lecture 4}
\lhead{09/30/21}

\begin{document}
\maketitle
\tableofcontents
\section{The $\pi-\lambda$ Theorem}
Let $(\Om, \F)$ be a measure space. Recall that a collection of sets $\Po$ is a $\pi$-system if $\Po$ is closed under finite intersection. A collection of sets $L$ is a $\lambda$-system if $\Om \in L$, $L$ is closed under complements and $L$ is closed under countable \emph{disjoint} unions. 

\begin{thrm}
    If $\Po$ is a $\pi$-system, $L$ is a $\lambda$-systam and $\Po \subseteq L$, then $\sigma(\Po) \subseteq L$.
\end{thrm}
\begin{ex}
    Consider the following $\Om = \{1,2,3,4\}$, $\F = \{A:A\subseteq \Om \}$. Define two probabilities $P_1, P_2 : \F \to [0,1]$ by $P_1(\w) = \frac{1}{4}$ for all $\w \in \Om$ and $P_2(\w) = \frac{1}{2}$ if $\w = 2,4$ and $P_2(\w) = 0$ otherwise. The collection $\G = \{\emptyset, \Om, \{1,2\}, \{3,4\}\}$ is $\lambda$-system but not a $\sigma$-algebra (or even an algebra). The two measures $P_1$ and $P_2$ agree on $\G$ but not on $\sigma(\G) = \F$. Note that the collection \[L = \{A \in \F : P_1(A) = P_2(A)\}\] is always a $\lambda$-system for any probabilities $P_1,P_2$. The $\pi-\lambda$ theorem lets us conclude that $L$ contains $\sigma(\Po)$ if $P_1$ and $P_2$ agree on $\Po$ and $\Po$ is a $\pi$-system.
\end{ex}
Note the following facts.

\underline{Fact 0}: If $L$ is a $\lambda$ system and $B_1,B_2 \in L$ with $B_1 \subseteq B_2$, then $B_2 \setminus B_1 \in L$. This is because $B_2 \setminus B_1 = B_2 \cap B_1^c = (B_2^c \cup B_1)^c$ and $B_2^c \cap B_1 = \emptyset$ since $B_1 \subseteq B_2$. Thus $L$ is closed under relative complements as well as complements.

\underline{Fact 1}: If $L$ is both a $\pi$-system and a $\lambda$-system, then $L$ is a $\sigma$-algebra. To see why this is, consider $(A_i)_{i=1}^\infty$ a countable collection of sets in $L$. Iteratively define $A_1'=A_1$ and $A_i' = A_i \cap (A_1'\cup\ldots \cup A_{i-1}')$. Since $L$ is both a $\pi$-system and a $\lambda$-system, $A_i' \in L$. Also $\bigcup_{i=1}^\infty A_i = \bigcup_{i=1}^\infty A_i' \in L$ since the sets $(A_i')_{i=1}^\infty$ are disjoint and $L$ is a $\lambda$-system. 

We will now prove the $\pi - \lambda$ theorem.
\begin{proof}
    Given $\Po$ a $\pi$-system and $L$ a $\lambda$-system with $\Po \subseteq L$, define $L_0$ to be the $\lambda$-system generated by $\Po$. We will show that $L_0$ is a $\pi$-system which by fact 1 will imply that $L_0$ is a $\sigma$-algebra and hence $\sigma(\Po) = L_0 \subseteq L$.

    For each $A \in L_0$, define $L_A = \{B : B \cap A \in L_0\}$. We will chose that $L_A$ is a $\lambda$-system. Note first that $\Om \in L_A$ since $A \in L_0$. Also if $B \in L_A$, then $A \cap B \in L_0$ and $A \cap B \subseteq A$. Thus since $L_0$ is a $\lambda$-system and closed under relative complements we have $A \setminus (A \cap B) = A \cap B^c$ is in $L_0$. Thus $B^c \in L_A$. Finally if $(B_i)_{i=1}^\infty$ is a countable collection of disjoint element of $L_A$, then $(A \cap B_i)_{i=1}^\infty$ is a countable collection of disjoint elements of $L_0$. Thus $\bigcup_{i=1}^\infty A \cap B_i = A \cap \left(\bigcup_{i=1}^\infty B_i \right) \in L_0$ and so $\bigcup_{i=1}^\infty B_i \in L_A$.

    If $A \in \Po$ and $B \in \Po$, then $A \cap B \in \Po \subseteq L_0$. Thus $B \in L_A$. Since $B$ was arbitrary, this means that $L_A$ is a $\lambda$-system that contains $\Po$ and hence $L_0 \subseteq L_A$ for every $A \in \Po$.

    Now if $A \in L_0$ and $B \in \Po$, then $L_0 \subseteq L_B$ and hence $B \cap A \in L_0$ which implies $B \in L_A$. Thus $L_A$ is a $\lambda$-system that contains $\Po$ and hence $L_0 \subseteq L_A$. But this means that for all $A,B \in L_0$, $A\cap B \in L_0$, thus $L_0$ is a $\lambda$-system.
\end{proof}
\section{Independence}
\begin{defn}
    Let $(\Om, \F, P)$ be a probability space. Let $\mathcal{C}_i \subseteq \F$ for each $i \in I$ (where $I$ is any index set). The collection $\{\mathcal{C}_i\}_{i \in I}$ are said to be \emph{independent} if for all finite subsets $J \subseteq I$ and every choice of $A_j \in \mathcal{C}_j$ for $j \in J$, we have 
    \[P\left(\bigcap_{j \in J}A_j\right) = \prod_{j \in J}P(A_j). \] 
\end{defn}
\begin{thrm}
    Suppose that $\{\mathcal{C}_i\}_{i\in I}$ are independent $\pi$-systems, then $\{\sigma(\mathcal{C}_i)\}_{i \in I}$ are independent.
\end{thrm}
\begin{proof}
    Since the definition of independence only use finite subsets of $I$ we may assume that $I = \{1,\ldots,n\}$ for some $n \in \N$. Define $\B_i = \mathcal{C}_i \cup \{\Om\}$, the collections $\B_i$ are still $\pi$-systems and $\sigma(\mathcal{C}_i)=\sigma(\B_i)$ so we will work with $\B_i$. Define
    \[L = \left\{B_1 \in \sigma(\B_i): \prod_{i=1}^n P(B_i) = P\left(\cap_{i=1}^n B_i\right) \text{ for all } B_2 \in \B_2,\ldots, B_n \in \B_n\right\}. \]
    We will show that $L$ is a $\lambda$-system. By the $\pi-\lambda$ theorem we will be able to conclude that $\sigma(\B_1) \subseteq L$. First note that $\Om \in L$ since $\{\B_i\}_{i=2}^n$ are independent. Suppose $B_1 \in L$, then 
    \[P(B_2 \cap \ldots \cap B_n) = P(B_1 \cap B_2 \cap \ldots \cap B_n)+P(B_1^c \cap B_2\cap \ldots \cap B_n). \]
    Rearranging we have 
    \[P(B_1^c \cap B_2\cap \ldots \cap B_n)= P(B_2 \cap \ldots \cap B_n) - P(B_1 \cap B_2 \cap \ldots \cap B_n).\]
    By our assumption that $\{\B_i\}_{i=2}^n$ are independent and that $B_1 \in L$, we have
    \begin{IEEEeqnarray*}{rCl}
        P(B_1^c \cap B_2\cap \ldots \cap B_n)&= &P(B_2 \cap \ldots \cap B_n) - P(B_1 \cap B_2 \cap \ldots \cap B_n)\\
        &=&\prod_{i=2}^n P(B_i) - \prod_{i=1}^n P(B_i)\\
        &=&(1-P(B_1))\prod_{i=2}^n P(B_i)\\
        &=& P(B_1^c)\prod_{i=2}^n P(B_i).
    \end{IEEEeqnarray*}
    and thus $B_1^c \in L$. Finally if $(B_{1,j})_{j=1}^\infty$ are in $L$ and disjoint, then set $B_1 = \bigcup_{j=1}^\infty B_{1,j}$ and note that
    \begin{IEEEeqnarray*}{rCl}
        P(B_1 \cap B_2 \cap \ldots B_n) &=& \sum_{j=1}^\infty P(B_{1,j} \cap B_2 \cap \ldots \cap B_n)\\
        &=& \sum_{j=1}^\infty P(B_{1,j})\prod_{i=2}^n P(B_i)\\
        &=&\left(\sum_{j=1}^\infty P(B_{1,j})\right)\prod_{i=2}^n P(B_i)\\
        &=&\prod_{i=1}^nP(B_i). 
    \end{IEEEeqnarray*}
    Thus $B_1 \in L$, $L$ is a $\lambda$-system and $\sigma(\B_1) = L$. We thus have that $\{\sigma(\B_1), \B_2,\ldots, \B_n\}$ is an independent collection. We can repeat this argument with 
    \[L_2 = \left\{B_2 \in \sigma(\B_2) : P\left(\bigcap_{i=1}^n B_2\right)=\prod_{i=1}^n P(B_i) \text{ for all } B_1 \in \sigma(\B_1) \text{ and } B_i \in \B_i, i = 3,\ldots, n \right\}. \]
    We will then conclude that $\sigma(\B_2) = L$. By induction we will prove that $\{\sigma(\B_i)\}_{i=1}^n$ is an independent collection.
\end{proof}
\begin{ex}
    Consider our coin tossing example $(\Om, \F, P) = ((0,1], \B, \lambda)$ where $\B$ is the collection of Borel sets and $\lambda$ is Lesbegue measure. The digits $d_i$ are independent in that if we set
    \[A_i = \{\Om, \emptyset, \{\w : d_i(\w)=1\}, \{\w : d_i(\w)=0\}\}, \]
    then $\{A_i\}_{i=1}^\infty$ are independent. The collections $\bigcup_{i=1}^\infty A_{2i}$ and $\bigcup_{i=1}^\infty A_{2i-1}$ are also independent and thus from $\w$ we can get two uniform $(0,1]$ samples 
    \[\w_1 = \sum_{i=1}^\infty 2^{-i}d_{2i}(\w) \text{ and } \w_2 = \sum_{i=1}^\infty 2^{-i}d_{2i-1}(\w). \]
    We can repeat this infinitely often to get a countable sequence of indpendent uniform $(0,1]$ random variables. We could use this to get any other iid sequence of real valued random variables.
\end{ex}
\section{Borel-Cantelli Lemmas}
Let $(\Om, \F, P)$ be a probability space. For $(A_i)_{i=1}^\infty$ in $\F$ define
\[A_i \; i.o. = \bigcap_{n=1}^\infty \bigcup_{m=n}^\infty A_m.\]
Thus $\w \in A_i \; i.o.$ if and only if $\w \in A_i$ for infinitely many $i$. That is $\w$ is  in $A_i$ \emph{infinitely often (i.o.)}. 
\begin{thrm}
    \emph{[Borel-Cantelli 1]} If $\sum_{i=1}^\infty P(A_i) < \infty$, then $P(A_i \; i.o.) = 0$.
\end{thrm}
\begin{proof}
    For every $n \in \N$, $A_i \; i.o. \subseteq \bigcup_{m=n}^\infty A_m$ and thus by countable subadditivity,
    \[P(A_i\;  i.o.) \le \sum_{m=n}^\infty P(A_m) \underset{n \to \infty}{\longrightarrow} 0. \qedhere \]
\end{proof}
\begin{ex}
    Let $(\Om, \F, P) = ((0,1], \B, \lambda)$, let $l_n(\w)$ be the length of the heads run starting at $n$. That is 
    \[\{\w:l_n(\w) = k\} = \{\w: d_n(\w)=d_{n+1}(\w)=\ldots=d_{n+k-1}(\w) =1 \text{ and } d_{n+k}(\w) = 0\}. \]
    Thus $P(\{l_n = k\}) = \frac{1}{2^{k+1}}$. Let $r_n$ be a sequence of positive integers and let $A_n = \{\w : l_n(\w) \ge r_n \}$. Then
    \[ P(A_n) = \sum_{k=0}^\infty \frac{1}{2^{r_n+k+1}} = \frac{1}{2^{r_n}}.\]
    By Borel-Cantelli, if $\sum_{n=1}^\infty \frac{1}{2^{r_n}} < \infty$, then $P(A_n \; i.o) = 0$. For example this is the case if $r_n = (1+\varepsilon)\log_2(n)$. 
\end{ex}
\begin{thrm}
    \emph{[Borel-Cantelli 2]} If $\sum_{i=1}^\infty P(A_i) = \infty$ and $\{A_i\}_{i=1}^\infty$ are independent, then 
    \[P(A_i \; i.o.) = 1. \]
\end{thrm}
\begin{proof}
    Note that $\left(A_i \; i.o.\right)^c = \bigcup_{n=1}^\infty \bigcap_{m=n}^\infty A_m^c$. Thus it suffices to show that for each $n \in \N$, we have $P\left(\bigcap_{m=n}^\infty A_m^c\right)=0$. Note that for all $n$ and $N$, we have
    \begin{IEEEeqnarray*}{rCl}
        P\left(\bigcap_{m=n}^\infty A_m^c\right) &\le& P\left(\bigcap_{m=n}^N A_m^c\right)\\
        &=& \prod_{m=n}^N P(A_m^c)\\
        &= & \prod_{m=n}^N (1-P(A_m))\\
        &\le& \prod_{m=n}^N \exp(P(A_m))\\
        &=&\exp\left(\sum_{m=n}^N P(A_m)\right)\\
        &\underset{N \to \infty}{\longrightarrow}& 0.
    \end{IEEEeqnarray*}
    Thus $P((A_i \; i.o.)^c)=0$.
\end{proof}
\begin{ex}
    As before let $l_n$ be the length of the heads run at $n$. For a sequnce of real number $x_i$, we have $\limsup_{i} x_i =l$ if and only if for all $\varepsilon > 0$, we have
    \begin{enumerate}
        \item For infinitely many $n$, $x_n \ge l -\varepsilon$, and
        \item For sufficiently large $n$, $x_n \le l +\varepsilon$.
    \end{enumerate}
    That is $\limsup_i x_i$ is the largest limit point of the sequence $x_i$. Using B.C. one and two, it can be shown that 
    \[\limsup_n \frac{l_n(\w)}{\log_2(n)} =1, \]
    with probability 1. We have already seen from B.C. 1, that with probability 1, for every $\varepsilon$, $l_n(\w) \le (1+\varepsilon)\log_2(n)$ for all but finitely many $n$.
\end{ex}
\end{document}